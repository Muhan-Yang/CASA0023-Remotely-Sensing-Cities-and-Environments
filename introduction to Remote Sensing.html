<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CASA0023 Learning Diary - 1&nbsp; Introduction to Remote Sensing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./introduction to Remote Sensing.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Remote Sensing</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CASA0023 Learning Diary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction to Remote Sensing.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Remote Sensing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="header-section-number">1.1</span> Summary</a>
  <ul class="collapse">
  <li><a href="#definitions" id="toc-definitions" class="nav-link" data-scroll-target="#definitions"><span class="header-section-number">1.1.1</span> definitions</a></li>
  <li><a href="#platforms" id="toc-platforms" class="nav-link" data-scroll-target="#platforms"><span class="header-section-number">1.1.2</span> Platforms</a></li>
  <li><a href="#sensor-types" id="toc-sensor-types" class="nav-link" data-scroll-target="#sensor-types"><span class="header-section-number">1.1.3</span> Sensor Types</a></li>
  <li><a href="#electromagnetic-radiation" id="toc-electromagnetic-radiation" class="nav-link" data-scroll-target="#electromagnetic-radiation"><span class="header-section-number">1.1.4</span> Electromagnetic Radiation</a></li>
  <li><a href="#data-formats" id="toc-data-formats" class="nav-link" data-scroll-target="#data-formats"><span class="header-section-number">1.1.5</span> Data Formats</a></li>
  <li><a href="#resolutions" id="toc-resolutions" class="nav-link" data-scroll-target="#resolutions"><span class="header-section-number">1.1.6</span> Resolutions</a></li>
  </ul></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications"><span class="header-section-number">1.2</span> Applications</a>
  <ul class="collapse">
  <li><a href="#snap" id="toc-snap" class="nav-link" data-scroll-target="#snap"><span class="header-section-number">1.2.1</span> SNAP</a></li>
  <li><a href="#sentinel" id="toc-sentinel" class="nav-link" data-scroll-target="#sentinel"><span class="header-section-number">1.2.2</span> Sentinel</a></li>
  <li><a href="#landsat" id="toc-landsat" class="nav-link" data-scroll-target="#landsat"><span class="header-section-number">1.2.3</span> Landsat</a></li>
  <li><a href="#using-r" id="toc-using-r" class="nav-link" data-scroll-target="#using-r"><span class="header-section-number">1.2.4</span> Using R</a></li>
  <li><a href="#practical-application-of-rs" id="toc-practical-application-of-rs" class="nav-link" data-scroll-target="#practical-application-of-rs"><span class="header-section-number">1.2.5</span> Practical Application of RS</a></li>
  </ul></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="header-section-number">1.3</span> Reflection</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">1.4</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Remote Sensing</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">1.1</span> Summary</h2>
<table class="table">
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Key Aspect</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="even">
<td><strong>Definitions</strong></td>
<td>Remote sensing as a technique for collecting Earth’s surface information from a distance.</td>
</tr>
<tr class="odd">
<td><strong>Platforms</strong></td>
<td>Satellites, planes, drones (“spectroradiometer”in a lab or in the field)used for data acquisition.</td>
</tr>
<tr class="even">
<td><strong>Sensor Types</strong></td>
<td>Passive and active sensors, their principles and examples.</td>
</tr>
<tr class="odd">
<td><strong>Electromagnetic Radiation</strong></td>
<td>Interaction with Earth’s surface and atmosphere.</td>
</tr>
<tr class="even">
<td><strong>Data Formats</strong></td>
<td>Focus on raster data and its applications.</td>
</tr>
<tr class="odd">
<td><strong>Resolutions</strong></td>
<td>Spatial, spectral, temporal, radiometric resolutions in remote sensing.</td>
</tr>
<tr class="even">
<td><strong>Applications</strong></td>
<td>Land cover, agriculture, climate change, disaster management.</td>
</tr>
</tbody>
</table>
<section id="definitions" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="definitions"><span class="header-section-number">1.1.1</span> definitions</h3>
<p>NASA defines remote sensing as <strong>the process of acquiring information from a distance</strong>, commonly associated with Earth Observation (EO), utilizing sensors on platforms like satellites, drones, and more. Currently, over 150 satellites equipped with these sensors orbit Earth, collecting essential data. However, the proliferation of space technology has led to a challenge with space debris, with NASA tracking over 27,000 pieces, underscoring the need for strategies to manage and mitigate space pollution.</p>
</section>
<section id="platforms" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="platforms"><span class="header-section-number">1.1.2</span> Platforms</h3>
<p>Remote sensing is accomplished using sensors mounted on various platforms, each offering unique capabilities for data collection from the Earth’s surface, atmosphere, and oceans:</p>
<ul>
<li><p><strong>Satellites:</strong>&nbsp;Capable of systematically covering vast areas, satellites revisit the same points on Earth from daily to every 16 days. This regular observation schedule is crucial for tracking environmental changes, weather patterns, and monitoring natural disasters on a global scale.</p></li>
<li><p><strong>Planes (aerial imagery):</strong>&nbsp;Provide targeted, high-resolution imagery for specific areas, making them invaluable for detailed surveys, agricultural assessments, and environmental monitoring.</p></li>
<li><p><strong>Drones:</strong>&nbsp;Offer unparalleled flexibility and precision, capturing detailed data at low altitudes for applications such as precision agriculture, construction monitoring, and environmental conservation.</p></li>
<li><p><strong>Phones:</strong>&nbsp;Enable widespread, citizen-driven data collection, contributing to urban studies, crowd-sourced mapping projects, and local environmental observations.</p></li>
<li><p><strong>Free standing on the ground or sea (with handheld devices):</strong>&nbsp;Ground and maritime platforms, like tripods, buoys, and hand-held devices, allow for direct, in-situ measurements of soil, water, and atmospheric conditions, essential for localized research and monitoring.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic1.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Various platforms and sensors used for remote sensing &nbsp;&nbsp;Source: Toth (2018)</em></p>
</section>
<section id="sensor-types" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="sensor-types"><span class="header-section-number">1.1.3</span> Sensor Types</h3>
<p>Remote sensing sensors are broadly classified into two categories based on their operational principles: passive and active sensors.</p>
<ul>
<li><p><strong>Passive Sensors:</strong>&nbsp;Capture energy naturally reflected or emitted by objects, relying on sunlight as the primary light source. Examples include <strong>cameras and satellite sensors</strong>, ideal for environmental monitoring and Earth observation during daylight hours.</p></li>
<li><p><strong>Active Sensors:</strong>&nbsp;Generate their own energy to illuminate targets, measuring the reflected energy. Technologies like <strong>LiDAR and radar</strong>&nbsp;fall into this category, enabling detailed surface mapping and atmospheric studies, regardless of day or night conditions.</p></li>
</ul>
<p>Choosing between passive and active sensors depends on the project’s goals, like desired detail, target area conditions, and when data is collected. <u>While passive sensors excel in natural light conditions, active sensors offer versatility in challenging environments (e.g., night-time or cloud-covered areas).</u> For example, Synthetic Aperture Radar (SAR) excels in overcoming challenges posed by clouds, volcanic ash, and darkness, thanks to its ability to operate at longer wavelengths across different bands (e.g., P, L, S, C, X, Ku, K). This versatility enhances Earth observation capabilities, enabling data acquisition in nearly all weather and lighting conditions.</p>
</section>
<section id="electromagnetic-radiation" class="level3" data-number="1.1.4">
<h3 data-number="1.1.4" class="anchored" data-anchor-id="electromagnetic-radiation"><span class="header-section-number">1.1.4</span> Electromagnetic Radiation</h3>
<p>Electromagnetic radiation (EMR) is essential for remote sensing, acting as the medium that carries information from the Earth’s surface to sensors located on satellites, aircraft, or ground-based platforms. EMR encompasses a spectrum of wavelengths, including visible light, infrared, and microwaves, each interacting uniquely with different surface materials and atmospheric conditions.</p>
<p>Fundamental Principles:</p>
<ul>
<li><p><strong>Wavelength (λ):</strong>&nbsp;The distance between consecutive wave peaks, determining the radiation’s energy and type.</p></li>
<li><p><strong>Frequency (ν):</strong>&nbsp;The number of wave cycles per second, inversely related to wavelength&nbsp;(λ=c/ν),&nbsp;where c is the speed of light (3×10⁸&nbsp;m/s)</p></li>
</ul>
<p>EMR propagates through space, carrying energy with oscillating electric and magnetic fields at right angles to each other and the direction of travel.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic2.png" class="img-fluid figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>How do electromagnetic waves wave&nbsp;&nbsp;&nbsp;Source: imathworks.com</em></p>
<p>Interaction with <strong>Earth’s Surface</strong>:</p>
<p>The interaction of electromagnetic radiation (EMR) with the Earth’s surface—encompassing <u>reflection, absorption, transmission and scattering</u>—fundamentally shapes the data captured by remote sensing technologies. Reflective properties reveal surface textures and compositions, absorption characteristics inform on material types and conditions, and transmission data offers insights into the substance’s transparency to specific EMR wavelengths.</p>
<p><strong>Atmospheric</strong>&nbsp;Influence:</p>
<p>While traversing the atmosphere, EMR may be scattered by particles or absorbed by gases, altering its path and intensity before reaching the surface.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic3.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Electromagnetic radiations’ interactions with Earth’s surface and atmosphere &nbsp;&nbsp;Source: Deepak Kumar Soni (2013)</em></p>
<p>Scattering Phenomena:</p>
<ul>
<li><p><strong>Rayleigh Scattering:</strong>&nbsp;Predominant when atmospheric particles are significantly smaller than the radiation’s wavelength, primarily affecting shorter wavelengths and coloring the sky blue.</p></li>
<li><p><strong>Mie Scattering:</strong> Arises when particle sizes are comparable to the wavelength, altering all wavelengths somewhat uniformly, noticeable during light’s passage through atmospheric pollutants or moisture.</p></li>
<li><p><strong>Non-selective Scattering:</strong> Manifests when particles exceed the radiation’s wavelength in size, impacting all wavelengths alike and contributing to clouds’ white appearance.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic4.png" class="img-fluid figure-img" style="width:55.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Comparison of visible wavelengths &nbsp;&nbsp;Source: vertebratepest.wordpress.com</em></p>
<p>Influence on Visual Perception:</p>
<p>Blue light scatters more intensely in Earth’s atmosphere due to its shorter wavelength, creating a blue sky and vivid sunsets with red and orange hues as the sun’s rays travel through more atmosphere. In contrast, the Moon’s lack of atmosphere results in a black sky and challenges in distance perception due to no scattering, while the ocean’s blue color arises from the absorption of longer wavelengths and scattering of shorter blue wavelengths, deepening in hue with increased depth.</p>
<p>Specular Reflection VS Diffuse Reflection</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic13-01.png" class="img-fluid figure-img" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Specular and diffuse reflection Source: Tempfli, K. et al.&nbsp;(2009)</em></p>
<ol type="1">
<li><p><strong>Specular Reflection</strong> occurs on smooth surfaces (like water or polished rocks), where light reflects in a single, specific direction. This reflection is directional, causing bright spots in images if the angle aligns with the sensor.</p></li>
<li><p><strong>Diffuse Reflection</strong> happens on rough surfaces (such as soil or vegetation), scattering light in multiple directions. This reflection is uniform, providing consistent information regardless of the viewing angle.</p></li>
<li><p><strong>Impact on Remote Sensing:</strong> The main difference is how they affect image brightness and information consistency. Specular reflection can vary with observer angle, leading to potential bright spots. Diffuse reflection offers reliable data about the Earth’s surface, useful for applications like vegetation monitoring or land cover classification.</p></li>
</ol>
<p>In the forthcoming studies, by exploring phenomena such as the Bidirectional Reflectance Distribution Function (BRDF), polarization, and fluorescence, we will gain a deeper understanding of the complexities of electromagnetic radiation’s interaction with the Earth’s surface...</p>
</section>
<section id="data-formats" class="level3" data-number="1.1.5">
<h3 data-number="1.1.5" class="anchored" data-anchor-id="data-formats"><span class="header-section-number">1.1.5</span> Data Formats</h3>
<p>Remote sensing data primarily uses raster formats, organizing the Earth’s surface into pixels, each representing specific information like reflectance or temperature. Key raster data formats include:</p>
<ul>
<li><p><strong>Band Interleaved by Line (BIL):</strong>&nbsp;Facilitates line-by-line analysis across multiple bands.</p></li>
<li><p><strong>Band Sequential (BSQ):</strong>&nbsp;Groups all pixels of a band together, suitable for single-band processing.</p></li>
<li><p><strong>Band Interleaved by Pixel (BIP):</strong>&nbsp;Stores all band values for each pixel together, ideal for multi-spectral analysis.</p></li>
</ul>
<p>Videro: Organizing Multi-band Image Data (BIL,BIP and BSQ Formats)</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/cJAN9un3r6I?si=Ugk7tK4BVG2hhC_S" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
</iframe>
<ul>
<li><p><strong>GeoTIFF:</strong> The most common format, incorporating geographic metadata, and widely supported across GIS and remote sensing platforms.</p></li>
<li><p><strong>LiDAR data:</strong>&nbsp;Capturing 3D point information, illustrates the adaptability of these formats for specific applications like elevation modeling.</p></li>
</ul>
</section>
<section id="resolutions" class="level3" data-number="1.1.6">
<h3 data-number="1.1.6" class="anchored" data-anchor-id="resolutions"><span class="header-section-number">1.1.6</span> Resolutions</h3>
<p>In remote sensing, data quality and applicability are determined by four key resolutions: spatial, spectral, temporal, and radiometric. Each plays a crucial role in how Earth observation data is captured, analyzed, and utilized.</p>
<p><strong>Spatial Resolution</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic5.png" class="img-fluid figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Source: gisgeography.com</em></p>
<p>Spatial resolution refers to the size of one pixel in a raster image, which can range from as fine as 10 cm to several kilometers. It determines the smallest object that can be detected on the Earth’s surface, with higher resolutions providing more detail.</p>
<p><strong>Spectral Resolution</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic6.png" class="img-fluid figure-img" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Source: gisgeography.com</em></p>
<p>Spectral resolution describes the ability of a sensor to define wavelength intervals or bands. It ranges from broad bands capturing basic color information in the visible spectrum to narrow bands that can identify specific spectral signatures of materials. Spectral signatures are unique to each feature on Earth but are limited by atmospheric windows that allow only certain wavelengths to pass through unabsorbed.</p>
<p><strong>Temporal Resolution</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic7.png" class="img-fluid figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Source: gisgeography.com</em></p>
<p>Temporal resolution is about the frequency at which a sensor revisits the same location, which can vary from multiple times a day to once every few weeks. This is vital for monitoring changes over time, such as vegetation growth, urban development, or the progression of natural disasters.</p>
<p><strong>Radiometric Resolution</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic8.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Source: USGS</em></p>
<p>Radiometric resolution indicates a sensor’s sensitivity to detect slight differences in light or reflectance levels, essentially the range of possible values a sensor can record. This can vary from 256 levels (8-bit) to over 2048 levels (11-bit), affecting the sensor’s ability to distinguish between similar surfaces.</p>
<p>Each type of resolution has its balancing act, influenced by the sensor’s design and the orbit type, whether geosynchronous or geostationary. The choice of sensor and its resolutions is dictated by the specific needs of a project, including <u>the size of features to be observed, the date range of interest, revisit requirements, spectral sensitivity, and budget constraints</u>. Understanding these resolutions is essential for selecting the appropriate remote sensing technology to answer specific scientific, environmental, or planning questions.</p>
</section>
</section>
<section id="applications" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="applications"><span class="header-section-number">1.2</span> Applications</h2>
<p>In the practical section, we learned how to download and process Sentinel and Landsat satellite data, and analyzed the downloaded data using QGIS, SNAP, and R software.</p>
<section id="snap" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="snap"><span class="header-section-number">1.2.1</span> SNAP</h3>
<p>SNAP (Sentinels Application Platform) is a free and open-source software platform developed by the European Space Agency (ESA) designed to provide comprehensive support for processing and analyzing data from the Sentinel satellite series. This platform is specifically aimed at earth observation data, offering a wide array of tools for the preprocessing, analysis, and visualization of remote sensing data.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic16.jpg" class="img-fluid figure-img" style="width:45.0%"></p>
</figure>
</div>
</div>
</div>
<p>The platform includes a series of toolboxes, each targeting specific data processing tasks such as image correction, classification, image synthesis, and change detection. These toolboxes offer a broad range of algorithms that enable users to perform complex analyses and interpretations of remote sensing data.</p>
</section>
<section id="sentinel" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="sentinel"><span class="header-section-number">1.2.2</span> Sentinel</h3>
<p>The Sentinel satellites are part of the Copernicus program, a cornerstone of the European Union’s efforts to monitor the Earth and its environment for the benefit of all European citizens. This fleet of satellites provides a unique set of observations, starting from high-resolution land and ocean monitoring (Sentinel-1 radar and Sentinel-2 optical sensors) to atmospheric composition (Sentinel-5P). Sentinel data is pivotal for a wide range of applications, including climate change, land use change detection, urban planning, and natural disaster assessment and management.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic15.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>SNAP is particularly well-suited for processing Sentinel data. It offers specialized toolboxes for Sentinel-1, Sentinel-2, and Sentinel-3, among others, facilitating tasks such as radar interferometry, land cover classification, and water color monitoring. These capabilities are enhanced by SNAP’s ability to handle the large data volumes produced by the Sentinel fleet, providing efficient data access and processing tools that cater to both scientific research and operational monitoring needs.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic14-02.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="landsat" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="landsat"><span class="header-section-number">1.2.3</span> Landsat</h3>
<p>While SNAP is primarily designed for Sentinel data, its flexibility and broad range of functionalities also make it useful for processing Landsat data, one of the longest-running sources of satellite imagery used for studying land changes over time. Landsat data complements Sentinel data by offering a historical perspective on land use and land cover changes, going back over four decades. This long-term dataset is invaluable for understanding environmental changes, assessing ecosystem health, and planning land management strategies.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic17.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Using SNAP for Landsat data involves leveraging its preprocessing, analysis, and visualization capabilities to manage Landsat’s multispectral imagery. Although SNAP does not include dedicated toolboxes for Landsat as it does for Sentinel satellites, its generic tools for raster data handling, image correction, and classification can be applied to Landsat images. This allows users to integrate Landsat data with Sentinel observations for comprehensive Earth observation analyses, offering a broader temporal and spectral range of environmental monitoring capabilities.</p>
</section>
<section id="using-r" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="using-r"><span class="header-section-number">1.2.4</span> Using R</h3>
<p>The process involves exporting Sentinel and Landsat data from SNAP as GeoTIFFs and shapefiles, then analyzing these in R using packages like <strong><code>terra</code></strong> for direct pixel value extraction. Custom R functions facilitate efficient processing and statistical analysis of spectral signatures for different land cover types. The analysis culminates in visualizing spectral signatures through density plots and comparative graphs, leveraging R’s graphical capabilities for detailed environmental analysis. This streamlined approach in R enhances the flexibility and depth of spectral analysis.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Rplot01.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="practical-application-of-rs" class="level3" data-number="1.2.5">
<h3 data-number="1.2.5" class="anchored" data-anchor-id="practical-application-of-rs"><span class="header-section-number">1.2.5</span> Practical Application of RS</h3>
<ul>
<li><p><strong>Urban Planning and Infrastructure Monitoring</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic9.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Remote Sensing and GIS Data Fusion &nbsp;&nbsp;Source:Talat Munshi (2013)</em></p>
<p>Utilizing spatial resolution principles, high-resolution imagery enables precise urban layout mapping and infrastructure changes over time, critical for sustainable urban development. GeoTIFF’s geographic metadata facilitates detailed spatial analyses in GIS platforms, optimizing land use and planning.</p></li>
<li><p><strong>Environmental Monitoring and Conservation</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic10.png" class="img-fluid figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Agriculture Mapping, Crop &amp; Plant Health &nbsp;&nbsp;Source: dronesurveycanada.ca</em></p>
<p>Informed by spectral resolution and EMR interactions, remote sensing precisely monitors ecosystem health, identifying vegetation types and assessing environmental changes. Multispectral and hyperspectral imagery, capturing extensive wavelength data, are essential for detailed environmental analyses.</p></li>
<li><p><strong>Disaster Response and Climate Change Tracking</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic11.png" class="img-fluid figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>SAR Flood Map for 2017 Uruguay Flooding &nbsp;Source: disasters.nasa.gov</em></p>
<p>Temporal resolution’s importance is underscored in disaster management and climate change studies, where SAR imagery’s all-weather capability ensures continuous monitoring. This is vital for quick disaster response and understanding long-term environmental trends.</p></li>
<li><p><strong>Navigating Atmospheric Challenges</strong></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pic12.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p><em>Atmospheric windows &nbsp;&nbsp;Source: noaa.gov</em></p>
<p>Addressing atmospheric absorption issues is crucial for uninterrupted Earth observation. Remote sensing techniques that penetrate atmospheric barriers enable consistent monitoring of the planet’s surface.&nbsp;For example: the places with limited or almost no absorption by the atmosphere is known as the atmospheric window, allowing us to peer into the atmosphere at various wavelengths.</p></li>
</ul>
</section>
</section>
<section id="reflection" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">1.3</span> Reflection</h2>
<p>As a master’s student specializing in Urban Spatial Science, I found my encounter with CASA0023 (Remotely Sensing Cities and Environments) to be truly fascinating. It has provided me with a fresh perspective that beautifully complements my prior studies in Geographic Information Systems (GIS) under CASA0005. This course illuminated the synergy between Remote Sensing (RS) and Geographic Information Systems (GIS), showcasing their combined strength in shaping my academic and professional path.</p>
<p>RS provides a broad perspective essential for environmental mapping, whereas GIS offers precision in spatial analysis, critical for urban planning. This shift from GIS’s detail-oriented analysis to RS’s wide-ranging observation highlights the complementary nature of spatial sciences.</p>
<p>Their collaboration is especially impactful in areas like disaster management and climate change, where integrating RS and GIS data leads to actionable insights for complex challenges.</p>
<p>Through CASA0023, I aimed to enrich my understanding of RS and GIS’s collaborative potential to address urban and environmental issues. Beyond gaining technical skills, this journey fostered a critical perspective on utilizing these technologies innovatively, aiming for sustainable solutions that consider their limitations and the complexity of their integration.</p>
</section>
<section id="references" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="references"><span class="header-section-number">1.4</span> References</h2>
<p>Drone Survey Canada, n.d. Drone Survey &amp; Aerial Survey Plant Variability. Available at: <a href="https://dronesurveycanada.ca/drone-survey-aerial-survey-plant-variability/" class="uri">https://dronesurveycanada.ca/drone-survey-aerial-survey-plant-variability/</a> [Accessed 13 January 2024].</p>
<p>GIS Geography, n.d. Remote Sensing Earth Observation Guide. Available at: <a href="https://gisgeography.com/remote-sensing-earth-observation-guide/" class="uri">https://gisgeography.com/remote-sensing-earth-observation-guide/</a> [Accessed 14 January 2024].</p>
<p>iMathWorks, n.d. How do electromagnetic waves wave. Available at: <a href="https://imathworks.com/physics/physics-how-do-electromagnetic-waves-wave/" class="uri">https://imathworks.com/physics/physics-how-do-electromagnetic-waves-wave/</a> [Accessed 13 January 2024].</p>
<p>Munshi, T., 2013. Built form, Travel Behaviour, and Low Carbon Development in Ahmedabad, India. DOI: 10.13140/2.1.1217.9845.</p>
<p>Soni, D., 2018. Estimation of Rainfall-Runoff in a Watershed Using Remote Sensing and GIS.</p>
<p>Spatial Post, 2023. Types of Platforms In Remote Sensing: A Comprehensive Guide. Available at: <a href="https://www.spatialpost.com/types-of-platforms-in-remote-sensing/#google_vignette" class="uri">https://www.spatialpost.com/types-of-platforms-in-remote-sensing/#google_vignette</a> [Accessed 13 January 2024].</p>
<p>Tempfli, K. et al., 2009. Principles of remote sensing: an introductory textbook. Enschede: International Institute for Geo-Information Science and Earth Observation.</p>
<p>Toth, C., 2018. The Future of Remote Sensing: Harnessing the Data Revolution. <em>GeoActa</em>, 42(2), pp.1-6.</p>
<p>USGS, n.d. What is Radiometric Resolution? Available at: <a href="https://www.usgs.gov/faqs/what-radiometric-resolution" class="uri">https://www.usgs.gov/faqs/what-radiometric-resolution</a> [Accessed 14 January 2024].&nbsp;</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>